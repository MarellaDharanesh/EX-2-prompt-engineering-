# EX-2-prompt-engineering-Comparative Analysis of different types of Prompting patterns and explain with Various Test scenerios
**1. **Objective****
To evaluate how different AI models respond to vague vs. refined prompts across scenarios, focusing on quality, accuracy, and depth of responses

**2. **Methodology**** The experiment follows these steps:
   1.Selecting AI Models: Various AI models (e.g., GPT-3.5, GPT-4, BERT, T5) are chosen for comparison.
   
   2.Defining Prompt Types: o Unstructured Prompts: Broad and ambiguous. o Refined Prompts: Clear and specific.
   
   3.Testing Across Scenarios: o Technical Explanation o Creative Writing o Troubleshooting o Decision-Making Analysis
   
   4.Evaluating Responses: Responses are measured based on: o Quality: Coherence and relevance. o Accuracy: Correctness of the information. o Depth: Level of detail provided.
**3. Results and Observations**
Scenario 1: Technical Explanation • Unstructured Prompt: “Tell me about AI.” o GPT-3.5: “AI is a technology that mimics human intelligence.” o GPT-4: “AI allows machines to perform tasks that typically require human intelligence.” • Refined Prompt: “What is the difference between supervised and unsupervised learning?” o GPT-3.5: “Supervised learning uses labeled data, whereas unsupervised learning identifies patterns in unlabeled data.” o GPT-4: “Supervised learning relies on pre-labeled datasets to make predictions, while unsupervised learning discovers hidden patterns without predefined labels.” Analysis: • Quality: Basic responses were more structured and informative. • Accuracy: Unstructured responses were vague, whereas refined responses were precise. • Depth: Refined responses provided more meaningful insights.

Scenario 2: Creative Writing • Unstructured Prompt: “Write a story.” o GPT-3.5: “Once upon a time, there was a robot.” o GPT-4: “A robot embarked on an adventure.” • Refined Prompt: “Write a story about a robot that discovers emotions.” o GPT-3.5: “A robot named R1-4 found a memory chip filled with human experiences, leading it to understand joy and sorrow.” o GPT-4: “R1-4, a highly efficient machine, encountered a diary that evoked emotions it was never programmed to feel, setting it on a journey of self-discovery.” Analysis: • Quality: Unstructured responses lacked creativity, while refined responses were engaging. • Accuracy: Unstructured responses were generic; refined responses were well-developed. • Depth: Refined responses included emotional and narrative depth.

Scenario 3: Troubleshooting • Unstructured Prompt: “Fix my computer.” o GPT-3.5: “Try restarting it.” o GPT-4: “Check if it’s plugged in and restart.” • Refined Prompt: “How do I troubleshoot a computer that won’t boot?” o GPT-3.5: “Ensure the power cable is connected, try booting in safe mode, and check for hardware failures.” o GPT-4: “Verify the power source, unplug external devices, access BIOS settings, and run diagnostics to check for faulty hardware.” Analysis: • Quality: Refined responses were more detailed and useful. • Accuracy: Unstructured responses were too generic; refined responses were actionable. • Depth: Refined responses covered multiple troubleshooting steps.

Scenario 4: Decision-Making Analysis • Unstructured Prompt: “What should I do?” o GPT-3.5: “Think about your options.” o GPT-4: “Make a list of pros and cons.” • Refined Prompt: “What factors should I consider before buying an electric car?” o GPT-3.5: “Evaluate costs, charging infrastructure, battery life, and incentives.” o GPT-4: “Consider daily commute, total cost of ownership, charging availability, environmental impact, government rebates, and longterm savings.” Analysis: • Quality: Unstructured responses were too generic; refined responses were well-thought-out. • Accuracy: Unstructured responses lacked key considerations; refined responses provided detailed factors. • Depth: Refined responses covered multiple relevant aspects.

**4. Key Findings**
Prompt Design Matters: Specific prompts significantly improve response quality.Model Performance: GPT-4 consistently outperformed GPT-3.5 in depth and nuance.User Guidance: Well-structured prompts enhance user engagement and understanding.Practical Applications: Thoughtful prompt engineering improves AI usability in real-world scenarios.

# OUTPUT
This study demonstrates that the clarity of prompts dramatically impacts AI responses. Well-defined prompts lead to more accurate, detailed, and useful outputs, reinforcing the importance of structured query formulation for optimizing AI performance.

# RESULT
A comparative analysis highlighting the importance of prompt refinement for improving AI-generated responses.

